import os
import json
from pathlib import Path
from typing import Optional, List, Dict, Any

os.environ.setdefault("KMP_DUPLICATE_LIB_OK", "TRUE")

import torch
import whisper
from moviepy.editor import VideoFileClip
from firebase_admin import credentials, db
import firebase_admin
from dotenv import load_dotenv

try:
    from faster_whisper import WhisperModel as FasterWhisperModel
except ImportError:  # pragma: no cover - optional dep
    FasterWhisperModel = None

load_dotenv()

# ------------------------------------
# ğŸ“Œ í”„ë¡œì íŠ¸ë³„ ì„¤ì •ê°’
# ------------------------------------
BASE_DIR = Path(__file__).resolve().parent
DEFAULT_CRED_PATH = BASE_DIR / "serviceAccountKey.json"

FIREBASE_DATABASE_URL = os.getenv("FIREBASE_DATABASE_URL")
FIREBASE_USER_ID = os.getenv("FIREBASE_USER_ID", "default_user")
INPUT_VIDEO_DIR = Path(os.getenv("STT_INPUT_VIDEO_DIR", BASE_DIR / "videos"))
OUTPUT_AUDIO_DIR = Path(os.getenv("STT_OUTPUT_AUDIO_DIR", BASE_DIR / "results/audio_wav"))
OUTPUT_JSON_DIR = Path(os.getenv("STT_OUTPUT_JSON_DIR", BASE_DIR / "results/stt_json"))
CREDENTIAL_PATH = Path(os.getenv("FIREBASE_CRED_PATH", DEFAULT_CRED_PATH))
WHISPER_MODEL_SIZE = os.getenv("WHISPER_MODEL_SIZE", "base")  # 'base', 'small', 'medium' ë“± ì„ íƒ
WHISPER_VERBOSE = os.getenv("WHISPER_VERBOSE", "false").lower() in {"1", "true", "yes", "on"}
STT_ENGINE = os.getenv("STT_ENGINE", "faster").lower()
if STT_ENGINE not in {"faster", "openai"}:
    STT_ENGINE = "faster"
WHISPER_DEVICE = os.getenv("WHISPER_DEVICE", "auto").lower()
FASTER_WHISPER_COMPUTE_TYPE = os.getenv("FASTER_WHISPER_COMPUTE_TYPE", "int8")

_WHISPER_MODEL = None
_FASTER_WHISPER_MODEL = None
_stt_progress = {"progress": 0, "stage": "idle"}
_stt_last_logged = {"progress": -1, "stage": ""}


def _clamp(value: int) -> int:
    return max(0, min(100, value))


def _resolve_device() -> str:
    if WHISPER_DEVICE != "auto":
        return WHISPER_DEVICE
    if torch.cuda.is_available():
        return "cuda"
    if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        return "mps"
    return "cpu"


def set_stt_progress(progress: Optional[int] = None, stage: Optional[str] = None):
    global _stt_last_logged
    if progress is not None:
        _stt_progress["progress"] = _clamp(progress)
    if stage:
        _stt_progress["stage"] = stage

    if (
        _stt_progress["progress"] != _stt_last_logged["progress"]
        or _stt_progress["stage"] != _stt_last_logged["stage"]
    ):
        print(f"[STT] { _stt_progress['progress']:>3}% - {_stt_progress['stage']}")
        _stt_last_logged = dict(_stt_progress)


def get_stt_progress():
    return dict(_stt_progress)


def reset_stt_progress():
    set_stt_progress(0, "idle")

# ------------------------------------
# 1. Firebase ì´ˆê¸°í™” ë° DB í•¨ìˆ˜
# ------------------------------------
def initialize_firebase() -> bool:
    """Firebase Admin SDKë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    try:
        if firebase_admin._apps:
            return True

        if not FIREBASE_DATABASE_URL:
            print("âš ï¸ FIREBASE_DATABASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False

        if not CREDENTIAL_PATH.exists():
            print(f"âš ï¸ Firebase ì„œë¹„ìŠ¤ í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CREDENTIAL_PATH}")
            return False

        cred = credentials.Certificate(str(CREDENTIAL_PATH))
        firebase_admin.initialize_app(cred, {'databaseURL': FIREBASE_DATABASE_URL})
        print("âœ… Firebase Admin SDK ì´ˆê¸°í™” ì™„ë£Œ.")
        return True
    except Exception as e:
        print(f"âŒ Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: ì˜¤ë¥˜: {e}")
        return False

def upload_to_firebase_text(user_id: str, file_name: str, stt_data: dict):
    """STT ì „ì‚¬ ê²°ê³¼ ì¤‘ 'full_text'ë§Œ DBì˜ stt_raw ê²½ë¡œì— ì—…ë¡œë“œí•©ë‹ˆë‹¤."""
    ref_path_text = f'users/{user_id}/presentations/{file_name}/stt_raw/full_text'
    ref_path_timestamps = f'users/{user_id}/presentations/{file_name}/stt_raw/timestamps'

    try:
        # 1. full_text ì €ì¥
        db.reference(ref_path_text).set(stt_data['full_text'])
        # 2. ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥
        db.reference(ref_path_timestamps).set(stt_data['words'])
        print(f"    -> [DB] í…ìŠ¤íŠ¸ ë° íƒ€ì„ìŠ¤íƒ¬í”„ ì—…ë¡œë“œ ì™„ë£Œ.")
        
    except Exception as e:
        print(f"    -> [DB] Firebase ì—…ë¡œë“œ ì‹¤íŒ¨. ì˜¤ë¥˜: {e}")

# ------------------------------------
# 2. ì˜¤ë””ì˜¤ ì¶”ì¶œ í•¨ìˆ˜
# ------------------------------------
def extract_audio(video_path: Path, output_audio_path: Path) -> bool:
    try:
        with VideoFileClip(str(video_path)) as video_clip:
            audio_clip = video_clip.audio
            audio_clip.write_audiofile(
                str(output_audio_path),
                codec='pcm_s16le',
                fps=16000,
                verbose=False,
                logger=None
            )
        return True
    except Exception as e:
        print(f"  âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return False

# ------------------------------------
# 3. Whisper STT ì „ì‚¬ ë° ë¶„ì„ ìë£Œ ìƒì„± í•¨ìˆ˜
# ------------------------------------
def get_whisper_model():
    global _WHISPER_MODEL
    if _WHISPER_MODEL is None:
        print(f"  -> [STT] Whisper {WHISPER_MODEL_SIZE} ëª¨ë¸ ë¡œë”© ì¤‘...")
        _WHISPER_MODEL = whisper.load_model(WHISPER_MODEL_SIZE)
    return _WHISPER_MODEL


def get_faster_whisper_model():
    global _FASTER_WHISPER_MODEL
    if FasterWhisperModel is None:
        raise RuntimeError("faster-whisper íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install faster-whisper")
    if _FASTER_WHISPER_MODEL is None:
        device = _resolve_device()
        if device == "mps":
            print("âš ï¸ faster-whisperëŠ” MPSë¥¼ ì§€ì›í•˜ì§€ ì•Šì•„ CPUë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. (.envì—ì„œ WHISPER_DEVICE=cpu ì§€ì • ê°€ëŠ¥)")
            device = "cpu"
        print(f"  -> [STT] faster-whisper {WHISPER_MODEL_SIZE} ëª¨ë¸ ë¡œë”© ì¤‘... (device={device}, compute={FASTER_WHISPER_COMPUTE_TYPE})")
        _FASTER_WHISPER_MODEL = FasterWhisperModel(
            WHISPER_MODEL_SIZE,
            device=device,
            compute_type=FASTER_WHISPER_COMPUTE_TYPE,
        )
    return _FASTER_WHISPER_MODEL


def transcribe_with_openai(audio_path: Path):
    print(f"  -> [STT] Whisper {WHISPER_MODEL_SIZE} (openai) ëª¨ë¸ ë¡œë”© ë° ì „ì‚¬ ì¤‘...")
    try:
        model = get_whisper_model()
        set_stt_progress(50, "Whisper ì¶”ë¡  ì¤‘")
        result = model.transcribe(
            str(audio_path),
            language="ko",
            word_timestamps=True,
            verbose=WHISPER_VERBOSE
        )

        full_text = result.get('text', '').strip()
        word_timestamps = []
        duration_sec = 0.0

        for segment in result.get('segments', []):
            if 'words' in segment:
                word_timestamps.extend(segment['words'])

        if word_timestamps:
            duration_sec = word_timestamps[-1].get('end', 0.0)

        analysis_data = {
            "full_text": full_text,
            "words": word_timestamps,
            "duration_sec": duration_sec,
            "word_count": len(word_timestamps)
        }

        print("  âœ… STT ì „ì‚¬ ì™„ë£Œ.")
        set_stt_progress(65, "STT ê²°ê³¼ ì •ë¦¬")
        return analysis_data

    except Exception as e:
        print(f"  âŒ Whisper ì „ì‚¬ ì‹¤íŒ¨: {e}")
        set_stt_progress(50, "Whisper ì˜¤ë¥˜")
        return None

# ------------------------------------
# 4. í†µí•© ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
# ------------------------------------
def process_single_video(
    video_path: Path,
    user_id: Optional[str] = None,
    output_audio_dir: Optional[Path] = None,
    output_json_dir: Optional[Path] = None,
    upload_to_firebase: bool = True,
    output_basename: Optional[str] = None,
):
    """ë‹¨ì¼ ì˜ìƒ íŒŒì¼ì— ëŒ€í•œ STT ë¶„ì„ ë° ê²°ê³¼ ì €ì¥."""
    set_stt_progress(0, "íŒŒì¼ ê²€ì¦")
    video_path = Path(video_path)
    if not video_path.exists():
        set_stt_progress(0, "íŒŒì¼ ì—†ìŒ")
        raise FileNotFoundError(f"ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

    user_id = user_id or FIREBASE_USER_ID
    output_audio_dir = Path(output_audio_dir or OUTPUT_AUDIO_DIR)
    output_json_dir = Path(output_json_dir or OUTPUT_JSON_DIR)

    output_audio_dir.mkdir(parents=True, exist_ok=True)
    output_json_dir.mkdir(parents=True, exist_ok=True)

    base_name = output_basename or video_path.stem
    audio_path = output_audio_dir / f"{base_name}.wav"
    txt_path = output_json_dir / f"{base_name}_text.txt"
    json_path = output_json_dir / f"{base_name}_analysis.json"

    set_stt_progress(5, "ì˜¤ë””ì˜¤ ì¶”ì¶œ")
    if not extract_audio(video_path, audio_path):
        set_stt_progress(5, "ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨")
        raise RuntimeError("ì˜¤ë””ì˜¤ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    set_stt_progress(30, "Whisper ë¡œë”©")
    stt_result = whisper_transcribe(audio_path)
    if not stt_result:
        set_stt_progress(30, "STT ì‹¤íŒ¨")
        raise RuntimeError("STT ì „ì‚¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    set_stt_progress(70, "ê²°ê³¼ ì €ì¥")
    try:
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(stt_result['full_text'])
        print(f"  âœ… í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {txt_path}")
    except Exception as e:
        print(f"  âŒ TXT íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    try:
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(stt_result, f, ensure_ascii=False, indent=4)
        print(f"  âœ… ë¶„ì„ ìë£Œ JSON ì €ì¥ ì™„ë£Œ: {json_path}")
    except Exception as e:
        print(f"  âŒ JSON íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    stt_result["file_paths"] = {
        "audio": str(audio_path),
        "text": str(txt_path),
        "json": str(json_path),
    }
    stt_result["base_name"] = base_name

    if upload_to_firebase:
        set_stt_progress(85, "Firebase ì—…ë¡œë“œ ì¤€ë¹„")
        is_firebase_ok = initialize_firebase()
        if is_firebase_ok:
            print("  [Step 4/4] Firebase DBì— í…ìŠ¤íŠ¸ ì—…ë¡œë“œ ì¤‘...")
            upload_to_firebase_text(user_id, base_name, stt_result)
        else:
            print("  âš ï¸ Firebase ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì•„ ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    set_stt_progress(100, "ì™„ë£Œ")
    return stt_result


def process_multiple_videos(input_dir, output_dir_audio, output_dir_json, user_id):
    input_dir = Path(input_dir)
    video_files = [f for f in input_dir.glob("*.mp4")]

    if not video_files:
        print(f"ê²½ê³ : '{input_dir}'ì—ì„œ ì²˜ë¦¬í•  MP4 ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ì´ {len(video_files)}ê°œì˜ ì˜ìƒì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì‚¬ìš©ì ID: {user_id}")

    for i, video_file in enumerate(video_files, start=1):
        print(f"\n--- [{i}/{len(video_files)}] {video_file.name} ì²˜ë¦¬ ì‹œì‘ ---")
        try:
            process_single_video(
                video_file,
                user_id=user_id,
                output_audio_dir=output_dir_audio,
                output_json_dir=output_dir_json,
            )
        except Exception as exc:
            print(f"  âŒ {video_file.name} ì²˜ë¦¬ ì‹¤íŒ¨: {exc}")

def transcribe_with_faster(audio_path: Path):
    try:
        model = get_faster_whisper_model()
        set_stt_progress(45, "faster-whisper ì¶”ë¡  ì¤€ë¹„")
        segments, info = model.transcribe(
            str(audio_path),
            language="ko",
            beam_size=5,
            word_timestamps=True
        )
        collected_segments: List[Any] = list(segments)
        set_stt_progress(55, "faster-whisper ì¶”ë¡  ì¤‘")

        full_text = " ".join(seg.text.strip() for seg in collected_segments).strip()
        word_timestamps: List[Dict[str, Any]] = []
        for seg in collected_segments:
            if seg.words:
                for word in seg.words:
                    word_timestamps.append({
                        "word": word.word.strip(),
                        "start": float(word.start) if word.start is not None else None,
                        "end": float(word.end) if word.end is not None else None,
                        "probability": float(getattr(word, "probability", 0.0))
                    })

        duration_sec = float(info.duration) if info and info.duration else 0.0
        if not duration_sec and word_timestamps:
            duration_sec = float(word_timestamps[-1].get("end") or 0.0)

        analysis_data = {
            "full_text": full_text,
            "words": word_timestamps,
            "duration_sec": duration_sec,
            "word_count": len(word_timestamps)
        }

        set_stt_progress(65, "STT ê²°ê³¼ ì •ë¦¬")
        return analysis_data
    except Exception as e:
        print(f"  âŒ faster-whisper ì „ì‚¬ ì‹¤íŒ¨: {e}")
        set_stt_progress(50, "Whisper ì˜¤ë¥˜")
        return None


def whisper_transcribe(audio_path: Path):
    if STT_ENGINE == "openai":
        return transcribe_with_openai(audio_path)
    result = transcribe_with_faster(audio_path)
    if result is None:
        print("âš ï¸ faster-whisper ì‹¤íŒ¨, ê¸°ë³¸ Whisperë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
        return transcribe_with_openai(audio_path)
    return result


if __name__ == "__main__":
    process_multiple_videos(INPUT_VIDEO_DIR, OUTPUT_AUDIO_DIR, OUTPUT_JSON_DIR, FIREBASE_USER_ID)
