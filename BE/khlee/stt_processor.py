import os
import json
import whisper
from moviepy.editor import VideoFileClip
from firebase_admin import credentials, db
import firebase_admin
import warnings
warnings.filterwarnings("ignore")

# -----------------------------------------------------------------
# ğŸ“Œ í”„ë¡œì íŠ¸ë³„ ì„¤ì •ê°’ (ìˆ˜ì • í•„ìˆ˜)
# -----------------------------------------------------------------
FIREBASE_DATABASE_URL = "https://csc4004-1-4-team04-default-rtdb.firebaseio.com/" 
USER_ID = "2021111985_JungHyeon"
CREDENTIAL_PATH = "/content/drive/MyDrive/AI_Coach_Data/Firebase_Keys/csc4004-1-4-team04-adminsdk.json" 
INPUT_VIDEO_DIR = "/content/drive/MyDrive/AI_Coach_Data/videos"
OUTPUT_AUDIO_DIR = "/content/drive/MyDrive/AI_Coach_Data/results/audio_wav"
OUTPUT_JSON_DIR = "/content/drive/MyDrive/AI_Coach_Data/results/stt_json"
WHISPER_MODEL_SIZE = "small" 
PAUSE_THRESHOLD_SEC = 2.0  # 2ì´ˆ ì´ìƒ ë¬´ìŒì€ ëŠê¹€ìœ¼ë¡œ ê¸°ë¡

# -----------------------------------------------------------------
# 1. WPM ë° ë¬´ìŒ êµ¬ê°„ ë¶„ì„ ë¡œì§ (2ì£¼ì°¨ í•µì‹¬ ê¸°ëŠ¥)
# -----------------------------------------------------------------
def analyze_voice_rhythm(stt_result_data: dict) -> dict:
    """
    STT ì „ì‚¬ ê²°ê³¼(ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ WPM ë° ë¬´ìŒ êµ¬ê°„ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    words = stt_result_data.get('words', [])
    total_duration = stt_result_data.get('duration_sec', 0.0)
    word_count = len(words)

    if not words or total_duration == 0:
         return {
            "wpm": 0, "pause_events": [], "avg_pause_duration": 0.0, "long_pause_count": 0,
            "full_text": stt_result_data.get('full_text', '') 
        }

    # WPM ê³„ì‚°
    wpm = round((word_count / total_duration) * 60) if total_duration > 0 else 0

    pause_events = []
    all_pause_durations = []
    
    for i in range(len(words) - 1):
        current_word_end = words[i].get('end', 0.0)
        next_word_start = words[i+1].get('start', 0.0)
        gap_duration = next_word_start - current_word_end
        
        if gap_duration > 0:
            all_pause_durations.append(gap_duration)
        
        # 2ì´ˆ ì´ìƒ ì§€ì†ë˜ëŠ” ë¬´ìŒ êµ¬ê°„ì„ 'ëŠê¹€'ìœ¼ë¡œ ê¸°ë¡
        if gap_duration >= PAUSE_THRESHOLD_SEC:
            pause_events.append({
                "start_sec": round(current_word_end, 2),
                "end_sec": round(next_word_start, 2),
                "duration": round(gap_duration, 2)
            })

    total_pause_duration = sum(all_pause_durations)
    total_pause_count = len(all_pause_durations)
    
    avg_pause_duration = round(total_pause_duration / total_pause_count, 2) if total_pause_count > 0 else 0.0
    long_pause_count = len(pause_events)

    # ğŸ“Œ API ëª…ì„¸ì„œì˜ voice_analysis êµ¬ì¡°ì— ë§ê²Œ ë°˜í™˜
    return {
        "wpm": wpm,
        "pause_events": pause_events,
        "avg_pause_duration": avg_pause_duration,
        "long_pause_count": long_pause_count,
        "full_text": stt_result_data.get('full_text', '') # 3ì£¼ì°¨ GPT ë¶„ì„ì„ ìœ„í•´ í…ìŠ¤íŠ¸ í¬í•¨
    }


# -----------------------------------------------------------------
# 2. Firebase ë° ê¸°íƒ€ ë³´ì¡° í•¨ìˆ˜ (ì´ì „ ë‹µë³€ê³¼ ë™ì¼)
# -----------------------------------------------------------------
def initialize_firebase():
    """Firebase Admin SDKë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    try:
        if not firebase_admin._apps: 
            cred = credentials.Certificate(CREDENTIAL_PATH)
            firebase_admin.initialize_app(cred, {'databaseURL': FIREBASE_DATABASE_URL})
        print("âœ… Firebase Admin SDK ì´ˆê¸°í™” ì™„ë£Œ.")
        return True
    except Exception as e:
        print(f"âŒ Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: ì˜¤ë¥˜: {e}")
        return False

def upload_to_firebase_analysis(user_id, file_name, analysis_result):
    """WPM ë¶„ì„ ê²°ê³¼ë§Œ Firebaseì˜ analysis_result ê²½ë¡œì— ì—…ë¡œë“œí•©ë‹ˆë‹¤."""
    # ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë  ê²½ë¡œ
    ref_path_analysis = f'users/{user_id}/presentations/{file_name}/voice_analysis' 

    try:
        # ğŸ“Œ full_textëŠ” ì œì™¸í•˜ê³  ë¶„ì„ ê²°ê³¼ë§Œ ì €ì¥
        analysis_data_to_save = analysis_result.copy()
        analysis_data_to_save.pop('full_text', None) 
        
        db.reference(ref_path_analysis).set(analysis_data_to_save)
        print(f"    -> [DB] WPM ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ ì™„ë£Œ.")
        
    except Exception as e:
        print(f"    -> [DB] Firebase ì—…ë¡œë“œ ì‹¤íŒ¨. ì˜¤ë¥˜: {e}")

def extract_audio(video_path, output_audio_path):
    # (ì˜¤ë””ì˜¤ ì¶”ì¶œ ë¡œì§ì€ ì´ì „ ë‹µë³€ê³¼ ë™ì¼)
    try:
        with VideoFileClip(video_path) as video_clip:
            audio_clip = video_clip.audio
            audio_clip.write_audiofile(
                output_audio_path, codec='pcm_s16le', fps=16000, verbose=False, logger=None
            )
        return True
    except Exception as e:
        print(f"  âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return False

def whisper_transcribe(audio_path):
    # (Whisper STT ì „ì‚¬ ë¡œì§ì€ ì´ì „ ë‹µë³€ê³¼ ë™ì¼)
    print(f"  -> [STT] Whisper {WHISPER_MODEL_SIZE} ëª¨ë¸ ë¡œë”© ë° ì „ì‚¬ ì¤‘...")
    try:
        model = whisper.load_model(WHISPER_MODEL_SIZE)
        result = model.transcribe(audio_path, language="ko", word_timestamps=True)
        
        full_text = result.get('text', '').strip()
        word_timestamps = []
        for segment in result.get('segments', []):
            if 'words' in segment:
                word_timestamps.extend(segment['words'])
                
        duration_sec = word_timestamps[-1].get('end', 0.0) if word_timestamps else 0.0
            
        return {
            "full_text": full_text, "words": word_timestamps,
            "duration_sec": duration_sec, "word_count": len(word_timestamps)   
        }

    except Exception as e:
        print(f"  âŒ Whisper ì „ì‚¬ ì‹¤íŒ¨: {e}")
        return None


# -----------------------------------------------------------------
# 3. í†µí•© ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ (ë©”ì¸ ë¡œì§) - ë¶„ì„ í†µí•©
# -----------------------------------------------------------------
def process_multiple_videos(input_dir, output_dir_audio, output_dir_json, user_id):
    
    is_firebase_ok = initialize_firebase()
    
    os.makedirs(output_dir_audio, exist_ok=True)
    os.makedirs(output_dir_json, exist_ok=True)
    video_files = [f for f in os.listdir(input_dir) if f.endswith('.mp4')]
    
    if not video_files:
        print(f"ê²½ê³ : '{input_dir}'ì—ì„œ ì²˜ë¦¬í•  MP4 ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ì´ {len(video_files)}ê°œì˜ ì˜ìƒì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì‚¬ìš©ì ID: {user_id}")
    
    for i, video_file in enumerate(video_files):
        print(f"\n--- [{i+1}/{len(video_files)}] {video_file} ì²˜ë¦¬ ì‹œì‘ ---")
        
        video_path = os.path.join(input_dir, video_file)
        base_name = os.path.splitext(video_file)[0]
        audio_path = os.path.join(output_dir_audio, f"{base_name}.wav")
        json_path = os.path.join(output_dir_json, f"{base_name}_analysis_data.json")

        # 1. ì˜¤ë””ì˜¤ ì¶”ì¶œ
        if not extract_audio(video_path, audio_path):
             continue

        # 2. Whisper STT ì „ì‚¬
        stt_data = whisper_transcribe(audio_path)
        
        if stt_data:
            # 3. WPM ë° ë¬´ìŒ êµ¬ê°„ ë¶„ì„ ìˆ˜í–‰ (2ì£¼ì°¨ í†µí•©)
            print("  [Step 3/4] WPM ë° ë¬´ìŒ êµ¬ê°„ ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
            voice_analysis_result = analyze_voice_rhythm(stt_data)

            # 4. ë¡œì»¬ JSON íŒŒì¼ ì €ì¥ (WPM ë¶„ì„ ê²°ê³¼ í¬í•¨)
            # JSON íŒŒì¼ì— STT ë°ì´í„°ì™€ WPM ë¶„ì„ ê²°ê³¼ë¥¼ ëª¨ë‘ í¬í•¨
            final_analysis_data = {
                "stt_raw": stt_data,
                "voice_analysis": voice_analysis_result
            }
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(final_analysis_data, f, ensure_ascii=False, indent=4)
            print(f"  âœ… ìµœì¢… ë¶„ì„ ìë£Œ JSON ì €ì¥ ì™„ë£Œ: {json_path}")
            
            # 5. Firebase DBì— WPM ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ
            if is_firebase_ok:
                print("  [Step 5/5] Firebase DBì— ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ ì¤‘...")
                upload_to_firebase_analysis(user_id, base_name, voice_analysis_result)
            
# --- ìµœì¢… ì‹¤í–‰ ---
process_multiple_videos(INPUT_VIDEO_DIR, OUTPUT_AUDIO_DIR, OUTPUT_JSON_DIR, USER_ID)
